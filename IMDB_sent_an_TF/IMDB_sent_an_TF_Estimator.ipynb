{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis on IMDB reviews: TensorFlow GloVe and LSTM with Estimator APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook represents more or less what was done with TF Estimators API with an LSTM based model on top of GloVe embedding on the 15.07.18 of my project. It is a stable version.\n",
    "\n",
    "In this notebook I will try to perform sentiment analysis using TensorFlow. Most of the notebook is a variation of what was done on this blog:\n",
    "https://www.oreilly.com/learning/perform-sentiment-analysis-with-lstms-using-tensorflow\n",
    "\n",
    "This is an upgrade of the previous notebook (IMDB_sent_an_TF_basic_improved1) where I'm replacing the basic APIs by custom Estimator level APIs. This includes in particular using `tf.estimator.Estimator` objects as well as `tf.data.Datasets` For this I follow the indications of these tutorials coming from the official documentation:\n",
    "\n",
    "https://www.tensorflow.org/get_started/premade_estimators\n",
    "\n",
    "https://www.tensorflow.org/get_started/datasets_quickstart\n",
    "\n",
    "https://www.tensorflow.org/get_started/custom_estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import io\n",
    "import tensorflow as tf\n",
    "#import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading pretrained embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pretrained embeddins from GloVe can be downloaded here: https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different **word embedding sizes**. The possibilities are 50, 100, 200, 300. We define the one we use next. On my personal machine, 100 seems to be the upper limit. With 200, I get `ResourceExhaustedError`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_emb_size = '100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_file_name = 'glove.6B/glove.6B.' + word_emb_size + 'd.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code of the next cell comes from https://stackoverflow.com/questions/37793118/load-pretrained-glove-vectors-in-python#45894001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "emb_df = pd.read_table(emb_file_name, sep=\" \",\n",
    "                       index_col=0, header=None, quoting=csv.QUOTE_NONE, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 100)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we transform the Pandas data frame into one list `words_list` containing the words (the indexes from the data frame) and one numpy array `word_vectors` containing the corresponding vectors. This last data frame will play the role of our **look-up table** later when we define our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_list = list(emb_df.index)\n",
    "word_vectors = emb_df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples with Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I commented this part because it is useless for the real task. It only serves a pedagogic purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseball_idx = words_list.index('baseball')\n",
    "#word_vectors[baseball_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_seq_len = 10 #Maximum length of sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first_sentence = np.zeros((max_seq_len), dtype='int32')\n",
    "#first_sentence[0] = words_list.index(\"i\")\n",
    "#first_sentence[1] = words_list.index(\"thought\")\n",
    "#first_sentence[2] = words_list.index(\"the\")\n",
    "#first_sentence[3] = words_list.index(\"movie\")\n",
    "#first_sentence[4] = words_list.index(\"was\")\n",
    "#first_sentence[5] = words_list.index(\"incredible\")\n",
    "#first_sentence[6] = words_list.index(\"and\")\n",
    "#first_sentence[7] = words_list.index(\"inspiring\")\n",
    "##first_sentence[8] and first_sentence[9] are going to be 0\n",
    "#print(first_sentence.shape)\n",
    "#print(first_sentence) #Shows the row index for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with tf.Session() as sess:\n",
    "#    print(tf.nn.embedding_lookup(word_vectors,first_sentence).eval().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we are looking for the threshold we should take as maximum length of a text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/home/aritz/Documents/CS_Programming_Machine_Learning/Machine_learning_and_AI/Online_courses/Fast_AI/fastai/courses/dl1/data/aclImdb/\"\n",
    "#PATH = \"/home/aritz/Documents/CS_Programming_Machine_Learning/Machine_learning_and_AI/Online_courses/Fast_AI/fastai/courses/dl1/data/aclImdb_sample2/\"\n",
    "TRAIN = PATH+'train/'\n",
    "TEST = PATH+'test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_POS = TRAIN + 'pos/'\n",
    "TRAIN_NEG = TRAIN + 'neg/'\n",
    "pos_files_trn = [TRAIN_POS + f for f in listdir(TRAIN_POS) if isfile(join(TRAIN_POS, f))]\n",
    "neg_files_trn = [TRAIN_NEG + f for f in listdir(TRAIN_NEG) if isfile(join(TRAIN_NEG, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_POS = TEST + 'pos/'\n",
    "TEST_NEG = TEST + 'neg/'\n",
    "pos_files_test = [TEST_POS + f for f in listdir(TEST_POS) if isfile(join(TEST_POS, f))]\n",
    "neg_files_test = [TEST_NEG + f for f in listdir(TEST_NEG) if isfile(join(TEST_NEG, f))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we determine the average number of words in one sample of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive files finished\n",
      "Negative files finished\n"
     ]
    }
   ],
   "source": [
    "n_words = []\n",
    "for pf in pos_files_trn:\n",
    "    with open(pf, \"r\", encoding='utf-8') as f:\n",
    "        line=f.readline()\n",
    "        counter = len(line.split())\n",
    "        n_words.append(counter)       \n",
    "print('Positive files finished')\n",
    "\n",
    "for nf in neg_files_test:\n",
    "    with open(nf, \"r\", encoding='utf-8') as f:\n",
    "        line=f.readline()\n",
    "        counter = len(line.split())\n",
    "        n_words.append(counter)  \n",
    "print('Negative files finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_files_trn = len(pos_files_trn) + len(neg_files_trn)\n",
    "n_files_test = len(pos_files_test) + len(neg_files_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strangely it seems that there aren't exactly 12500 files in the folders indicated below, as it is supposed to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12501\n",
      "12501\n",
      "12501\n",
      "12500\n"
     ]
    }
   ],
   "source": [
    "print(len(pos_files_trn))\n",
    "print(len(neg_files_trn))\n",
    "print(len(pos_files_test))\n",
    "print(len(neg_files_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of files is 25002\n",
      "The total number of words in the files is 5809599\n",
      "The average number of words in the files is 232.37466501339946\n"
     ]
    }
   ],
   "source": [
    "print('The total number of files is', n_files_trn)\n",
    "print('The total number of words in the files is', sum(n_words))\n",
    "print('The average number of words in the files is', sum(n_words)/len(n_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we plot an histogram of the number of words in each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(n_words, 50)\n",
    "plt.xlabel('Sequence Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axis([0, 1200, 0, 8000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at this, 250 words seems a good choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping words to indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we map words to indexes using our words_list variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we do it for a specific file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We display the content of the file (i.e. the real text).  (I commented out this part because it is useless for the real task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fname = pos_files_trn[3] #Can use any valid index (not just 3)\n",
    "#with open(fname) as f:\n",
    "#    for lines in f:\n",
    "#        print(lines)\n",
    "#        exit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removes punctuation, parentheses, question marks, etc., and leaves only alphanumeric characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "strip_special_chars = re.compile(\"[^A-Za-z0-9 ]+\")\n",
    "\n",
    "def clean_sentences(string):\n",
    "    string = string.lower().replace(\"<br />\", \" \")\n",
    "    return re.sub(strip_special_chars, \"\", string.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We map the given file to a list of indexes where each indexe corresponds to a word, according to the list `words_list`. (I commented out this part because it is useless for the real task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first_file = np.zeros((max_seq_len), dtype='int32')\n",
    "#with open(fname) as f:\n",
    "#    idx_counter = 0\n",
    "#    line=f.readline()\n",
    "#    cleaned_line = clean_sentences(line)\n",
    "#    split = cleaned_line.split()\n",
    "#    for word in split:\n",
    "#        try:\n",
    "#            first_file[idx_counter] = words_list.index(word)\n",
    "#        except ValueError:\n",
    "#            first_file[idx_counter] = 399999 #Vector for unknown words\n",
    "#        idx_counter = idx_counter + 1\n",
    "#first_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ids_train will be a matrix, which contains for each file of the training set (first the positive ones, then the negative ones) a row where the columns contain the indices corresponding to the words of the sample file.\n",
    "\n",
    "The whole computation of the transformation of each text file into a list of indices takes time and needs to be performed only once. The result is saved after the first time and then reloaded for all the other executions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ids_train = np.zeros((n_files_trn, max_seq_len), dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_counter = 0\n",
    "#for pf in pos_files_trn:\n",
    "#    with open(pf, \"r\") as f:\n",
    "#        idx_counter = 0\n",
    "#        line=f.readline()\n",
    "#        cleaned_line = clean_sentences(line)\n",
    "#        split = cleaned_line.split()\n",
    "#        for word in split:\n",
    "#            try:\n",
    "#                ids_train[file_counter][idx_counter] = words_list.index(word)\n",
    "#            except ValueError:\n",
    "#                ids_train[file_counter][idx_counter] = 399999 #Vector for unkown words\n",
    "#            idx_counter = idx_counter + 1\n",
    "#            if idx_counter >= max_seq_len:\n",
    "#                break\n",
    "#        file_counter = file_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for nf in neg_files_trn:\n",
    "#    with open(nf, \"r\") as f:\n",
    "#        idx_counter = 0\n",
    "#        line=f.readline()\n",
    "#        cleaned_line = clean_sentences(line)\n",
    "#        split = cleaned_line.split()\n",
    "#        for word in split:\n",
    "#            try:\n",
    "#                ids_train[file_counter][idx_counter] = words_list.index(word)\n",
    "#            except ValueError:\n",
    "#                ids_train[file_counter][idx_counter] = 399999 #Vector for unkown words\n",
    "#            idx_counter = idx_counter + 1\n",
    "#            if idx_counter >= max_seq_len:\n",
    "#                break\n",
    "#        file_counter = file_counter + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pass into embedding function and see if it evaluates. \n",
    "\n",
    "#np.save('idsMatrixTrain'+word_emb_size, ids_train)\n",
    "\n",
    "ids_train = np.load('idsMatrixTrain'+word_emb_size+'.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25002, 250)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ids_test = np.zeros((n_files_test, max_seq_len), dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_counter = 0\n",
    "#for pf in pos_files_test:\n",
    "#    with open(pf, \"r\") as f:\n",
    "#        idx_counter = 0\n",
    "#        line=f.readline()\n",
    "#        cleaned_line = clean_sentences(line)\n",
    "#        split = cleaned_line.split()\n",
    "#        for word in split:\n",
    "#            try:\n",
    "#                ids_test[file_counter][idx_counter] = words_list.index(word)\n",
    "#            except ValueError:\n",
    "#                ids_test[file_counter][idx_counter] = 399999 #Vector for unkown words\n",
    "#            idx_counter = idx_counter + 1\n",
    "#            if idx_counter >= max_seq_len:\n",
    "#                break\n",
    "#        file_counter = file_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for nf in neg_files_test:\n",
    "#    with open(nf, \"r\") as f:\n",
    "#        idx_counter = 0\n",
    "#        line=f.readline()\n",
    "#        cleaned_line = clean_sentences(line)\n",
    "#        split = cleaned_line.split()\n",
    "#        for word in split:\n",
    "#            try:\n",
    "#                ids_test[file_counter][idx_counter] = words_list.index(word)\n",
    "#            except ValueError:\n",
    "#                ids_test[file_counter][idx_counter] = 399999 #Vector for unkown words\n",
    "#            idx_counter = idx_counter + 1\n",
    "#            if idx_counter >= max_seq_len:\n",
    "#                break\n",
    "#        file_counter = file_counter + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('idsMatrixTest'+word_emb_size, ids_test)\n",
    "\n",
    "ids_test = np.load('idsMatrixTest'+word_emb_size+'.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we also create the **labels** with **one-hot-encoding** ([1, 0] for positive and [0, 1] for negative), as done in the original notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_pos_trn = len(pos_files_trn)\n",
    "len_neg_trn = len(neg_files_trn)\n",
    "y_train = [[1,0] for i in range(len_pos_trn)] + [[0,1] for i in range(len_neg_trn)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_pos_test = len(pos_files_test)\n",
    "len_neg_test = len(neg_files_test)\n",
    "y_test = [[1,0] for i in range(len_pos_test)] + [[0,1] for i in range(len_neg_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_trn = len_pos_trn + len_neg_trn\n",
    "len_test = len_pos_test + len_neg_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that some premade estimators do not accept one-hot-encoding of the labels as explained here:https://stackoverflow.com/questions/48114258/tensorflow-estimator-number-of-classes-does-not-change\n",
    "\n",
    "For this reason I create a function which converts a list containing one-hot-incoded labels into a list containing **ordinal encoded** labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_2_ordinal(onehot):\n",
    "    n_classes = len(onehot[0])\n",
    "    ordinal = []\n",
    "    for i in range(len(onehot)):\n",
    "        for j in range(n_classes):\n",
    "            if onehot[i][j]==1:\n",
    "                ordinal.append(j)\n",
    "    return(ordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ord = onehot_2_ordinal(y_train)\n",
    "y_test_ord = onehot_2_ordinal(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimator APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we create a model using the Estimator APIs from TF. One of the advantage of this higher level of APIs is that some things done manualy when using TF basic APIs, are done automatically. There is no need to initialize variables for instance, or defining writers for TensorBoard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define the **input functions**. They are the objects which supply data for training, evaluating, and prediction to the model. They are using `tf.data.Dataset` objects which are one of the key tools of TF. These objects allow to access the data and manipulate it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the body of the next function, it is important that the argument of the `shuffle` method is equal to the length of the whole training data set. See entry of the 11.07.18 of my journal for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features is a numpy array of shape (#samples, 250)\n",
    "def train_input_fn(features, labels, batch_size):\n",
    "    \"\"\"An input function for training\"\"\"\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(({'Indexes':features}, labels))\n",
    "\n",
    "    # Shuffle, repeat, and batch the examples.\n",
    "    dataset = dataset.shuffle(len_trn).repeat().batch(batch_size)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features is a numpy array of shape (#samples, 250)\n",
    "def eval_input_fn(features, labels, batch_size):\n",
    "    \"\"\"An input function for evaluation or prediction\"\"\"\n",
    "    if labels is None:\n",
    "        # No labels, use only features.\n",
    "        inputs = {'Indexes':features}\n",
    "    else:\n",
    "        inputs = ({'Indexes':features}, labels)\n",
    "\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
    "\n",
    "    # Batch the examples\n",
    "    assert batch_size is not None, \"batch_size must not be None\"\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define the **feature columns**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_feature_columns = []\n",
    "my_feature_columns.append(tf.feature_column.numeric_column(key='Indexes', shape=max_seq_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define the **directory where to store the log files for TensorBoard** as well as the checkpoint file, the model files, and the graph file. These last files enable the notebook to **automatically store and restaure** previously trained models (as long as the architecture is the same in the old and the new notebook), as explained in this tutorial:\n",
    "\n",
    "https://www.tensorflow.org/guide/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '/home/aritz/Documents/CS_Programming_Machine_Learning/Projects/IMDB_sentiment_analysis/IMDB_sent_an_TF/Saved_models/Basic_LSTM_'+word_emb_size+'d/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to define a custom estimator we need to define a **model function**. For this we mix the code of the notebook based only on basic TF APIs together with some parts of the script of this tutorial: https://www.tensorflow.org/get_started/custom_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_model(features, labels, mode, params):\n",
    "    # Use `input_layer` to apply the feature columns.\n",
    "    input_data = tf.feature_column.input_layer(features, params['feature_columns'])\n",
    "    # The next line is required because tf.feature_column.input_layer\n",
    "    # outputs tf.float32 (whatever the input)\n",
    "    # and tf.nn.embedding_lookup requires\n",
    "    # tf.int32\n",
    "    input_data = tf.cast(input_data, tf.int32)\n",
    "    # Transform each index in a sentence into the associated vector\n",
    "    data = tf.nn.embedding_lookup(word_vectors, input_data)\n",
    "    # The following line is a fixe coming from this page:\n",
    "    # https://github.com/tgjeon/TensorFlow-Tutorials-for-Time-Series/issues/2\n",
    "    # in order to prevent an error appearing next.\n",
    "    data = tf.cast(data, tf.float32)\n",
    "    # Next we define the LSTM\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(params['lstm_units'])\n",
    "    lstm_cell = tf.contrib.rnn.DropoutWrapper(cell=lstm_cell, output_keep_prob=params['keep_prob'])\n",
    "    value, _ = tf.nn.dynamic_rnn(lstm_cell, data, dtype=tf.float32)\n",
    "    # swaps the two first dimensions so it has dimensions [max_time, batch_size, cell.output_size]\n",
    "    value = tf.transpose(value, [1, 0, 2])\n",
    "    # If I'm not mistaken the next cell slices the part of \n",
    "    # the output which corresponds to the last output of the lstm, \n",
    "    # or in other words the output corresponding to the \n",
    "    # last word for every sample (if I'm right we used \n",
    "    # 0 padding and cut everything which goes beyound 250 words, \n",
    "    # so technically it is the 250th output). \n",
    "    # My guess is that last has dimensions [batch_size, cell.output_size] \n",
    "    # which we can then use to do matrix multiplication \n",
    "    # with weight which has dimensions [cell.output_size, numClasses] \n",
    "    # (remember that cell.output_size=lstm_units).\n",
    "    last = tf.gather(value, int(value.get_shape()[0]) - 1)\n",
    "    # We apply an affine transformation to get the logits\n",
    "    #weight = tf.Variable(tf.truncated_normal([params['lstm_units'], params['n_classes']]))\n",
    "    #bias = tf.Variable(tf.constant(0.1, shape=[params['n_classes']]))\n",
    "    #logits = (tf.matmul(last, weight) + bias)\n",
    "    logits = tf.layers.dense(inputs=last, units=2)\n",
    "    # Maybe I could  replace this last part using tf.layers.dense:\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/layers/dense\n",
    "    \n",
    "    # The following lines are actually independent of the achitecture\n",
    "    # of the model.\n",
    "    \n",
    "    # Compute predictions.\n",
    "    predicted_classes = tf.argmax(logits, 1)\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {\n",
    "            'class_ids': predicted_classes[:, tf.newaxis],\n",
    "            'probabilities': tf.nn.softmax(logits),\n",
    "            'logits': logits,\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "    \n",
    "    # Compute loss\n",
    "    \n",
    "    # Note that because of this function, we have to\n",
    "    # provide ordinaly encoded labels and not one-hot-encoded\n",
    "    # labels, as explained on this page:\n",
    "    # https://stackoverflow.com/questions/48114258/tensorflow-estimator-number-of-classes-does-not-change\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "    \n",
    "    # Compute evaluation metrics.\n",
    "    accuracy = tf.metrics.accuracy(labels=labels,\n",
    "                                   predictions=predicted_classes,\n",
    "                                   name='acc_op')\n",
    "    metrics = {'accuracy': accuracy}\n",
    "    tf.summary.scalar('loss', loss)\n",
    "    tf.summary.scalar('accuracy', accuracy[1])\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode, loss=loss, eval_metric_ops=metrics)\n",
    "    \n",
    "    # Create training op.\n",
    "    assert mode == tf.estimator.ModeKeys.TRAIN\n",
    "\n",
    "    optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
    "    train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can define the **custom estimator**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_num_worker_replicas': 1, '_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': '', '_task_type': 'worker', '_is_chief': True, '_model_dir': '/home/aritz/Documents/CS_Programming_Machine_Learning/Projects/IMDB_sentiment_analysis/IMDB_sent_an_TF/Saved_models/Basic_LSTM_100d/', '_save_checkpoints_secs': 600, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f30fd2bf7f0>, '_global_id_in_cluster': 0, '_service': None, '_log_step_count_steps': 100, '_task_id': 0, '_save_checkpoints_steps': None, '_master': '', '_tf_random_seed': None, '_save_summary_steps': 100, '_keep_checkpoint_max': 5, '_num_ps_replicas': 0, '_session_config': None}\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.estimator.Estimator(\n",
    "        model_fn=my_model,\n",
    "        model_dir=model_dir,\n",
    "        params={\n",
    "            'feature_columns': my_feature_columns,\n",
    "            'n_classes': 2,\n",
    "            'lstm_units': 64,\n",
    "            'keep_prob': 0.7\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluation of the Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = int(100)\n",
    "train_steps = int(8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can **train** our Estimator. Note that for the function `tf.losses.sparse_softmax_cross_entropy`, that we are using in the model function, requires the **label** to be **ordinaly encoded and not one-hot-encoded** as explained here:\n",
    "\n",
    "https://stackoverflow.com/questions/48114258/tensorflow-estimator-number-of-classes-does-not-change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /home/aritz/.local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aritz/.local/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /home/aritz/Documents/CS_Programming_Machine_Learning/Projects/IMDB_sentiment_analysis/IMDB_sent_an_TF/Saved_models/Basic_LSTM_100d/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.8403634, step = 0\n",
      "INFO:tensorflow:global_step/sec: 5.75768\n",
      "INFO:tensorflow:loss = 0.68872017, step = 100 (17.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.27479\n",
      "INFO:tensorflow:loss = 0.7099755, step = 200 (15.937 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.48786\n",
      "INFO:tensorflow:loss = 0.68436676, step = 300 (15.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.54203\n",
      "INFO:tensorflow:loss = 0.6871506, step = 400 (15.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.51199\n",
      "INFO:tensorflow:loss = 0.6914494, step = 500 (15.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.5306\n",
      "INFO:tensorflow:loss = 0.6863657, step = 600 (15.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.55944\n",
      "INFO:tensorflow:loss = 0.6673574, step = 700 (15.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.54118\n",
      "INFO:tensorflow:loss = 0.67521757, step = 800 (15.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.57471\n",
      "INFO:tensorflow:loss = 0.68820906, step = 900 (15.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.59626\n",
      "INFO:tensorflow:loss = 0.6747464, step = 1000 (15.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.57759\n",
      "INFO:tensorflow:loss = 0.6854734, step = 1100 (15.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.66588\n",
      "INFO:tensorflow:loss = 0.5668668, step = 1200 (15.002 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.59152\n",
      "INFO:tensorflow:loss = 0.54389715, step = 1300 (15.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.6381\n",
      "INFO:tensorflow:loss = 0.5116727, step = 1400 (15.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.63503\n",
      "INFO:tensorflow:loss = 0.39399675, step = 1500 (15.071 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.61722\n",
      "INFO:tensorflow:loss = 0.43165627, step = 1600 (15.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.56645\n",
      "INFO:tensorflow:loss = 0.34971738, step = 1700 (15.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.14558\n",
      "INFO:tensorflow:loss = 0.31176934, step = 1800 (16.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.43771\n",
      "INFO:tensorflow:loss = 0.3856309, step = 1900 (15.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.252\n",
      "INFO:tensorflow:loss = 0.32393628, step = 2000 (15.995 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.11624\n",
      "INFO:tensorflow:loss = 0.38139167, step = 2100 (19.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.35741\n",
      "INFO:tensorflow:loss = 0.31600043, step = 2200 (18.665 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.33166\n",
      "INFO:tensorflow:loss = 0.3384341, step = 2300 (18.756 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.29632\n",
      "INFO:tensorflow:loss = 0.36520404, step = 2400 (15.882 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.26763\n",
      "INFO:tensorflow:loss = 0.30129614, step = 2500 (15.955 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.29074\n",
      "INFO:tensorflow:loss = 0.38753346, step = 2600 (15.897 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.29167\n",
      "INFO:tensorflow:loss = 0.42432368, step = 2700 (15.893 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.27955\n",
      "INFO:tensorflow:loss = 0.3747335, step = 2800 (15.925 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.28744\n",
      "INFO:tensorflow:loss = 0.37678733, step = 2900 (15.905 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.2394\n",
      "INFO:tensorflow:loss = 0.33637267, step = 3000 (16.027 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.29818\n",
      "INFO:tensorflow:loss = 0.42162332, step = 3100 (15.878 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.2776\n",
      "INFO:tensorflow:loss = 0.34811938, step = 3200 (15.930 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.95422\n",
      "INFO:tensorflow:loss = 0.23092687, step = 3300 (16.795 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.36288\n",
      "INFO:tensorflow:loss = 0.34452224, step = 3400 (18.647 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.41986\n",
      "INFO:tensorflow:loss = 0.4223284, step = 3500 (18.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.12005\n",
      "INFO:tensorflow:loss = 0.27850044, step = 3600 (16.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.2383\n",
      "INFO:tensorflow:loss = 0.31858838, step = 3700 (16.030 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3724 into /home/aritz/Documents/CS_Programming_Machine_Learning/Projects/IMDB_sentiment_analysis/IMDB_sent_an_TF/Saved_models/Basic_LSTM_100d/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 5.84788\n",
      "INFO:tensorflow:loss = 0.3390536, step = 3800 (17.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.24541\n",
      "INFO:tensorflow:loss = 0.3668272, step = 3900 (16.012 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.0608\n",
      "INFO:tensorflow:loss = 0.28200567, step = 4000 (16.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.2625\n",
      "INFO:tensorflow:loss = 0.35369578, step = 4100 (15.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.29364\n",
      "INFO:tensorflow:loss = 0.33048648, step = 4200 (15.889 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.06979\n",
      "INFO:tensorflow:loss = 0.4858873, step = 4300 (16.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.26869\n",
      "INFO:tensorflow:loss = 0.24620634, step = 4400 (15.953 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.2738\n",
      "INFO:tensorflow:loss = 0.33360586, step = 4500 (15.939 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.02285\n",
      "INFO:tensorflow:loss = 0.19751985, step = 4600 (16.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.47285\n",
      "INFO:tensorflow:loss = 0.22568148, step = 4700 (18.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.0036\n",
      "INFO:tensorflow:loss = 0.4036854, step = 4800 (16.656 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.29441\n",
      "INFO:tensorflow:loss = 0.2912749, step = 4900 (15.887 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.2897\n",
      "INFO:tensorflow:loss = 0.35262042, step = 5000 (15.899 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.27016\n",
      "INFO:tensorflow:loss = 0.28675836, step = 5100 (15.948 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.31543\n",
      "INFO:tensorflow:loss = 0.257179, step = 5200 (15.834 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.28724\n",
      "INFO:tensorflow:loss = 0.22484896, step = 5300 (15.905 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.28214\n",
      "INFO:tensorflow:loss = 0.37514153, step = 5400 (15.918 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.27117\n",
      "INFO:tensorflow:loss = 0.3497205, step = 5500 (15.946 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.31155\n",
      "INFO:tensorflow:loss = 0.23993544, step = 5600 (15.844 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.26891\n",
      "INFO:tensorflow:loss = 0.32905862, step = 5700 (15.952 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.2439\n",
      "INFO:tensorflow:loss = 0.3323028, step = 5800 (16.016 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.26633\n",
      "INFO:tensorflow:loss = 0.38334823, step = 5900 (15.958 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.28335\n",
      "INFO:tensorflow:loss = 0.25586274, step = 6000 (15.915 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.28065\n",
      "INFO:tensorflow:loss = 0.24993455, step = 6100 (15.922 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.25947\n",
      "INFO:tensorflow:loss = 0.2824943, step = 6200 (15.976 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.14425\n",
      "INFO:tensorflow:loss = 0.31258947, step = 6300 (16.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.43441\n",
      "INFO:tensorflow:loss = 0.29678312, step = 6400 (18.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.38449\n",
      "INFO:tensorflow:loss = 0.28639597, step = 6500 (18.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.48263\n",
      "INFO:tensorflow:loss = 0.31730384, step = 6600 (18.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.12825\n",
      "INFO:tensorflow:loss = 0.27995518, step = 6700 (16.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.25598\n",
      "INFO:tensorflow:loss = 0.32629147, step = 6800 (15.985 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.2836\n",
      "INFO:tensorflow:loss = 0.19501169, step = 6900 (15.915 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.25884\n",
      "INFO:tensorflow:loss = 0.3205092, step = 7000 (15.977 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.27431\n",
      "INFO:tensorflow:loss = 0.31244582, step = 7100 (15.938 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.29282\n",
      "INFO:tensorflow:loss = 0.23150901, step = 7200 (15.891 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.22657\n",
      "INFO:tensorflow:loss = 0.24141067, step = 7300 (16.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.31804\n",
      "INFO:tensorflow:loss = 0.1653386, step = 7400 (15.827 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7402 into /home/aritz/Documents/CS_Programming_Machine_Learning/Projects/IMDB_sentiment_analysis/IMDB_sent_an_TF/Saved_models/Basic_LSTM_100d/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 6.02933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.25588658, step = 7500 (16.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.27166\n",
      "INFO:tensorflow:loss = 0.25691232, step = 7600 (15.944 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.26681\n",
      "INFO:tensorflow:loss = 0.26699427, step = 7700 (15.957 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.23971\n",
      "INFO:tensorflow:loss = 0.18709126, step = 7800 (16.027 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.28186\n",
      "INFO:tensorflow:loss = 0.28253007, step = 7900 (15.919 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8000 into /home/aritz/Documents/CS_Programming_Machine_Learning/Projects/IMDB_sentiment_analysis/IMDB_sent_an_TF/Saved_models/Basic_LSTM_100d/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.35129797.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7f30fd2bf0f0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.train(\n",
    "    input_fn=lambda:train_input_fn(features=ids_train, labels=y_train_ord, batch_size=batch_size),\n",
    "    steps=train_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can evaluate our model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-07-15-10:44:30\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/aritz/Documents/CS_Programming_Machine_Learning/Projects/IMDB_sentiment_analysis/IMDB_sent_an_TF/Saved_models/Basic_LSTM_100d/model.ckpt-8000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-07-15-10:44:51\n",
      "INFO:tensorflow:Saving dict for global step 8000: accuracy = 0.8570057, global_step = 8000, loss = 0.3316556\n"
     ]
    }
   ],
   "source": [
    "eval_test = classifier.evaluate(input_fn=lambda:eval_input_fn(features=ids_test,\n",
    "                                                                    labels=y_test_ord,\n",
    "                                                                    batch_size=batch_size)\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we print the **accuracy of the model on the test set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set accuracy: 0.857\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.8570057, 'loss': 0.3316556, 'global_step': 8000}\n"
     ]
    }
   ],
   "source": [
    "print(eval_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section I will implement a loop which will train the model as long as the quality of the prediction keeps improving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = int(100)\n",
    "train_steps = int(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_i = 0\n",
    "acc_iplus1 = 0\n",
    "acc_iplus2 = eval_test['accuracy']\n",
    "num_iter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aritz/.local/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/aritz/Documents/CS_Programming_Machine_Learning/Projects/IMDB_sentiment_analysis/IMDB_sent_an_TF/Saved_models/Basic_LSTM_100d/model.ckpt-12000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 12001 into /home/aritz/Documents/CS_Programming_Machine_Learning/Projects/IMDB_sentiment_analysis/IMDB_sent_an_TF/Saved_models/Basic_LSTM_100d/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.116583526, step = 12000\n",
      "INFO:tensorflow:global_step/sec: 5.52669\n",
      "INFO:tensorflow:loss = 0.24673532, step = 12100 (18.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.42818\n",
      "INFO:tensorflow:loss = 0.1551571, step = 12200 (18.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.73969\n",
      "INFO:tensorflow:loss = 0.15166456, step = 12300 (17.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.5761\n",
      "INFO:tensorflow:loss = 0.34310123, step = 12400 (15.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.50861\n",
      "INFO:tensorflow:loss = 0.11865516, step = 12500 (15.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.46593\n",
      "INFO:tensorflow:loss = 0.3100912, step = 12600 (15.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.84718\n",
      "INFO:tensorflow:loss = 0.13938998, step = 12700 (17.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.45558\n",
      "INFO:tensorflow:loss = 0.15073161, step = 12800 (15.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.60011\n",
      "INFO:tensorflow:loss = 0.24637079, step = 12900 (15.151 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13000 into /home/aritz/Documents/CS_Programming_Machine_Learning/Projects/IMDB_sentiment_analysis/IMDB_sent_an_TF/Saved_models/Basic_LSTM_100d/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.17228603.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-07-15-11:38:52\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/aritz/Documents/CS_Programming_Machine_Learning/Projects/IMDB_sentiment_analysis/IMDB_sent_an_TF/Saved_models/Basic_LSTM_100d/model.ckpt-13000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-07-15-11:39:15\n",
      "INFO:tensorflow:Saving dict for global step 13000: accuracy = 0.84956604, global_step = 13000, loss = 0.42755738\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/aritz/Documents/CS_Programming_Machine_Learning/Projects/IMDB_sentiment_analysis/IMDB_sent_an_TF/Saved_models/Basic_LSTM_100d/model.ckpt-13000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 13001 into /home/aritz/Documents/CS_Programming_Machine_Learning/Projects/IMDB_sentiment_analysis/IMDB_sent_an_TF/Saved_models/Basic_LSTM_100d/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.1351165, step = 13000\n",
      "INFO:tensorflow:global_step/sec: 5.78828\n",
      "INFO:tensorflow:loss = 0.11435699, step = 13100 (17.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.47174\n",
      "INFO:tensorflow:loss = 0.13042718, step = 13200 (15.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.45931\n",
      "INFO:tensorflow:loss = 0.10244565, step = 13300 (15.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.97935\n",
      "INFO:tensorflow:loss = 0.04903977, step = 13400 (16.724 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.16554\n",
      "INFO:tensorflow:loss = 0.23376682, step = 13500 (16.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.52103\n",
      "INFO:tensorflow:loss = 0.1585369, step = 13600 (15.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.12519\n",
      "INFO:tensorflow:loss = 0.21807069, step = 13700 (16.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.14174\n",
      "INFO:tensorflow:loss = 0.16492325, step = 13800 (16.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.24359\n",
      "INFO:tensorflow:loss = 0.118033655, step = 13900 (16.016 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14000 into /home/aritz/Documents/CS_Programming_Machine_Learning/Projects/IMDB_sentiment_analysis/IMDB_sent_an_TF/Saved_models/Basic_LSTM_100d/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.1796388.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-07-15-11:43:08\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/aritz/Documents/CS_Programming_Machine_Learning/Projects/IMDB_sentiment_analysis/IMDB_sent_an_TF/Saved_models/Basic_LSTM_100d/model.ckpt-14000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-07-15-11:43:31\n",
      "INFO:tensorflow:Saving dict for global step 14000: accuracy = 0.8447662, global_step = 14000, loss = 0.47048092\n"
     ]
    }
   ],
   "source": [
    "while ((acc_iplus2 > acc_iplus1) or (acc_iplus2 > acc_i)):\n",
    "    num_iter = num_iter + 1\n",
    "    classifier.train(\n",
    "    input_fn=lambda:train_input_fn(features=ids_train, labels=y_train_ord, batch_size=batch_size),\n",
    "    steps=train_steps)\n",
    "    acc_i = acc_iplus1\n",
    "    acc_iplus1 = acc_iplus2\n",
    "    eval_test = classifier.evaluate(input_fn=lambda:eval_input_fn(features=ids_test,\n",
    "                                                                    labels=y_test_ord,\n",
    "                                                                    batch_size=batch_size)\n",
    "                                     )\n",
    "    acc_iplus2 = eval_test['accuracy']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.83672655\n",
      "0.8407664\n",
      "0.83468664\n"
     ]
    }
   ],
   "source": [
    "print(acc_i)\n",
    "print(acc_iplus1)\n",
    "print(acc_iplus2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to track the progress of the model on TensorBoard it is enough to enter \"tensorboard --logdir (...)\" in a terminal with \"(...)\" replaced by the name of the directory where the event files are saved, and visiting http://localhost:6006/ with a browser.\n",
    "\n",
    "With custom estimators it is enough to include lines like\n",
    "`tf.summary.scalar('loss', loss)`\n",
    "in the model function in order to track the quantities we are interested in. An event file for TensorBoard will be updated every 100 steps during the training with the `train` method (at least it is what I observe from my empirical experience), and a single event file measuring the state of the tracked variable will be written when calling the `evaluate`method. There is no need to define a writer with `tf.summary.FileWriter`.\n",
    "\n",
    "**Caveat emptor:** This being said, I often ran into problems with TensorBoard. No files were being written, or only during the evaluation phase. Currently it seems to work as I described above, but I cannot garantee that what I described is absolutely true. I don't know yet how to specify the behaviour of an Estimator object when it comes to TensorBoard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cells I use TF basic APIs to access directly what is happening when I call the train method of my Estimator object. This allows me to understand source of errors and warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = int(100)\n",
    "lstm_units = int(64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by defining **two datasets**. One for the training and one for the testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = train_input_fn(features=ids_train, labels=y_train_ord, batch_size=batch_size)\n",
    "dataset_test = eval_input_fn(features=ids_test, labels=y_test_ord, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define the **reinitializable iterator**. Unlike One-shot iterators, they alow to switch from one dataset to another one. As explained here:\n",
    "https://www.tensorflow.org/programmers_guide/datasets#creating_an_iterator, \n",
    "\"A reinitializable iterator is defined by its structure. We could use the\n",
    " `output_types` and `output_shapes` properties of either `dataset_train`\n",
    " or `dataset_test` here, because they are compatible.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = tf.data.Iterator.from_structure(dataset_train.output_types,\n",
    "                                           dataset_train.output_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = iterator.get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell contains the model itself (this part is similar to what is found in the model function of the Estimator object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = tf.feature_column.input_layer(features, my_feature_columns)\n",
    "input_data = tf.cast(input_data, tf.int32)\n",
    "data = tf.nn.embedding_lookup(word_vectors, input_data)\n",
    "data = tf.cast(data, tf.float32)\n",
    "lstm_cell = tf.contrib.rnn.BasicLSTMCell(lstm_units)\n",
    "lstm_cell = tf.contrib.rnn.DropoutWrapper(cell=lstm_cell, output_keep_prob=0.8)\n",
    "value, _ = tf.nn.dynamic_rnn(lstm_cell, data, dtype=tf.float32)\n",
    "value = tf.transpose(value, [1, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last = tf.gather(value, int(value.get_shape()[0]) - 1)\n",
    "#weight = tf.Variable(tf.truncated_normal([lstm_units, 2]))\n",
    "#bias = tf.Variable(tf.constant(0.1, shape=(2,)))\n",
    "#logits = (tf.matmul(last, weight) + bias)\n",
    "logits = tf.layers.dense(inputs=last, units=2)\n",
    "predicted_classes = tf.argmax(logits, 1)\n",
    "loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "accuracy = tf.metrics.accuracy(labels=labels,\n",
    "                                   predictions=predicted_classes,\n",
    "                                   name='acc_op')\n",
    "optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
    "train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.summary.scalar('accuracy', accuracy[1])\n",
    "tf.summary.scalar('loss', loss)\n",
    "merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next operation is required in order to use reinitializable iterators but not for simple one-shot iterator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_op_train = iterator.make_initializer(dataset_train)\n",
    "init_op_test = iterator.make_initializer(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_debug = tf.InteractiveSession()\n",
    "sess_debug.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason it seems to be necessary to add the following line though it wasn't in the original script. Otherwise I optain a FailedPreconditionError."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_debug.run(tf.local_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_train = tf.summary.FileWriter(model_dir+'Basic_log/Plot_train/', sess_debug.graph)\n",
    "writer_test = tf.summary.FileWriter(model_dir+'Basic_log/Plot_test/', sess_debug.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do the **training** of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(15):\n",
    "    print('Epoch {}'.format(j))\n",
    "    # Initialize an iterator over the training dataset.\n",
    "    sess_debug.run([init_op_train])\n",
    "    print('Training')\n",
    "    for i in range(100):\n",
    "        sess_debug.run(train_op)\n",
    "        if (i % 50 == 0):  \n",
    "            summary, acc = sess_debug.run([merged, accuracy])\n",
    "            print(\"Accuracy = {}\".format(acc[1]))\n",
    "            writer_train.add_summary(summary, j*100)\n",
    "    \n",
    "    print('Testing')\n",
    "    # Initialize an iterator over the testing dataset.\n",
    "    sess_debug.run(init_op_test)\n",
    "    sess_debug.run(merged)\n",
    "    summary, acc = sess_debug.run([merged, accuracy])\n",
    "    print(\"Accuracy = {}\".format(acc[1]))\n",
    "    writer_test.add_summary(summary, j*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_debug.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
